import os
import json
import hashlib
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from .utils.os_detection import detect_os
from .utils.package_manager import list_packages, get_package_info
from .utils.downloader import download_source
from .utils.hash_calculator import calculate_file_hash
from .utils.swhid_calculator import calculate_swhid

class Scanner:
    def __init__(self, threads=4, output_dir="ossa_reports", temp_dir="/tmp/ossa_temp"):
        self.output_dir = output_dir
        self.temp_dir = temp_dir
        self.os_type = detect_os()
        self.threads = threads
        os.makedirs(self.temp_dir, exist_ok=True)

    def process_package(self, package):
        try:
            print(f"Processing package: {package}")
            package_info = get_package_info(self.os_type, package)
            print(f"Fetched metadata for {package}")

            source_file = download_source(self.os_type, package, self.temp_dir)
            print(f"Downloaded source file: {source_file}")

            file_hash = calculate_file_hash(source_file)
            print(f"Hash (SHA256) for {package}: {file_hash}")

            # Extract source code directory in temp_dir
            source_dir = os.path.join(self.temp_dir, package)
            os.makedirs(source_dir, exist_ok=True)

            # Calculate SWHID
            swhid = calculate_swhid(source_dir)
            print(f"SWHID for {package}: {swhid}")

            # Save report
            self.save_package_report(package, package_info, file_hash, swhid, source_file)

        except Exception as e:
            print(f"Error processing package {package}: {e}")

    def scan_packages(self):
        """
        Scans all packages in the repository and processes them in parallel.
        """
        print(f"Detected OS: {self.os_type}")
        print("Listing available packages...")
        packages = list_packages(self.os_type)
        with ThreadPoolExecutor(max_workers=self.threads) as executor:
            # Submit tasks for parallel processing
            future_to_package = {
                executor.submit(self.process_package, package): package
                for package in packages
            }

            for future in as_completed(future_to_package):
                package = future_to_package[future]
                try:
                    future.result()
                except Exception as e:
                    print(f"Exception occurred for package {package}: {e}")

    def save_package_report(self, package, package_info, file_hash, swhid, source_file):
        """
        Save the report for a single package.

        Args:
            package (str): Package name.
            package_info (dict): Information about the package.
            file_hash (str): SHA256 hash of the downloaded source.
            swhid (str): Software Heritage ID of the package.
        """
        # Generate report filename
        date_str = datetime.now().strftime("%Y%m%d")
        report_filename = f"ossa-{date_str}-{hash(package) % 10000}-{package}.json"
        report_path = os.path.join(self.output_dir, report_filename)

        # This need to be moved to a different class
        artifact_name = source_file
        if "tmp/" in source_file:
            artifact_name = os.path.basename(source_file)
        if "--" in artifact_name:
            artifact_name = artifact_name.split("--")[-1]

        # Create the report content
        report = {
            "id": f"OSSA-{date_str}-{hash(package) % 10000}",
            "version": "1.0.0",
            "severity": package_info.get("severity", []),
            "title": f"Advisory for {package}",
            "package_name": package,
            "publisher": "Generated by OSSA Collector",
            "last_updated": datetime.now().isoformat(),
            "approvals": [{"consumption": True, "externalization": True}],
            "description": f"Automatically generated OSSA for the package {package}.",
            "purls": [f"pkg:{self.os_type}/{package}"],
            "regex": [f"^pkg:{self.os_type}/{package}.*"],
            "affected_versions": ["*.*"],
            "artifacts": [
                {
                    "url": f"file://{artifact_name}",
                    "hashes": {
                        "sha1": file_hash['sha1'], "sha256": file_hash['sha256'], 
                        "ssdeep": file_hash['ssdeep'], "swhid": file_hash['swhid']},
                    "swhid": swhid
                }
            ],
            "licenses": package_info.get("licenses", []),
            "aliases": package_info.get("aliases", []),
            "references": package_info.get("references", [])
        }

        # Save the report to the output directory
        with open(report_path, "w") as f:
            json.dump(report, f, indent=4)
        print(f"Report saved: {report_path}")
