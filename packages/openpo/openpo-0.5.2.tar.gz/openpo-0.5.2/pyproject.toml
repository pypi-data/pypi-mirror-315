[tool.poetry]
name = "openpo"
version = "0.5.2"
description = "Build high quality synthetic datasets with AI feedback from 200+ LLMs"
authors = ["Daniel Lee <dannylee1020@gmail.com>"]
license = "Apache-2.0"
keywords = ["llm", "finetuning", "ai", "rlaif", "preference tuning", "synthetic data generation", "synthetic data"]
include = ["LICENSE", "README.md"]
repository = "https://github.com/dannylee1020/openpo"
documentation="https://docs.openpo.dev"
readme = "README.md"

[tool.poetry.dependencies]
python = ">=3.10.1,<4.0"
pydantic = "^2.9.2"
boto3 = "^1.35.57"
numpy = "^1.26.4"
huggingface-hub = "^0.26.2"
httpx = "^0.27.2"
datasets = "^3.1.0"
pandas = "^2.2.3"

[tool.poetry.group.eval.dependencies]
llm-blender = "^0.0.2"
prometheus-eval = "^0.1.20"
vllm = "^0.6.4.post1"
openai = "^1.57.1"
anthropic = "^0.40.0"

[tool.poetry.group.docs.dependencies]
mkdocs-material = "^9.5.44"
mkdocstrings-python = "^1.12.2"

[tool.poetry.extras]
eval = ["llm-blender", "prometheus-eval", "vllm", "openai", "anthropic"]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

