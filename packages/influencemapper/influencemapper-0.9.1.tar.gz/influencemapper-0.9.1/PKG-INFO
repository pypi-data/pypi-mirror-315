Metadata-Version: 2.3
Name: influencemapper
Version: 0.9.1
Summary: A tool for extracting information from disclosure statements.
Author-email: Hardy <hardy.oei@gmail.com>
License-Expression: MIT
License-File: LICENSE
Keywords: competing interest,conflict of interests,disclosure,research
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Natural Language :: English
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Requires-Python: >=3.9
Requires-Dist: attrs==24.2.0
Requires-Dist: beautifulsoup4==4.12.3
Requires-Dist: fuzzywuzzy==0.18.0
Requires-Dist: jupyterlab==4.2.5
Requires-Dist: lxml==5.3.0
Requires-Dist: nltk==3.9.1
Requires-Dist: openai==1.41.0
Requires-Dist: pandas==1.5.3
Requires-Dist: pydantic==2.8.2
Requires-Dist: python-levenshtein==0.26.1
Requires-Dist: spacy==3.7.6
Requires-Dist: tiktoken==0.7.0
Requires-Dist: tqdm==4.66.5
Description-Content-Type: text/markdown

# InfluenceMapper

InfluenceMapper is a python library for extracting disclosure information from scholarly articles. It uses fine-tuned OpenAI's GPT models for the extraction of entities and relationships from the text. The functions included in the library are:
- Extract entities from the text.
- Extract relationships between authors and entities.
- Extract relationships between entities and the study.

## Installation

To install the library, run the following command:

```bash
pip install influencemapper
```

## Training the model

The model is trained on a dataset of scholarly articles. The dataset is available at the `data` folder. To train the model, clone the directory and run the following command:

```bash
python core/src/influencemapper/cli.py fine_tune -train_data data/train.jsonl -valid_data data/valid.jsonl -model_name gpt-4o-mini -threshold 1500 study_org 
python core/src/influencemapper/cli.py fine_tune -train_data data/train.jsonl -valid_data data/valid.jsonl -model_name gpt-4o-mini -threshold 1500 author_org
```

As of the writing of this README, the resulting file has to be uploaded manually to the OpenAI platform to fine-tune the model. The model will be available for use after the fine-tuning process is completed.The `threshold` parameter is used to restrict samples, allowing only those with a maximum token count that meets the training requirements to pass.

## Inferring entities and relationships

To infer entities and relationships from a disclosure text, run the following command:

```bash 
python core/src/influencemapper/cli.py infer -data data/test.jsonl -model_name gpt-4o-mini -API_KEY [API_KEY] study_org
python core/src/influencemapper/cli.py infer -data data/test.jsonl -model_name gpt-4o-mini -API_KEY [API_KEY] author_org
```

To get the results, you have to visit the OpenAI platform and download the results. After dowlnoading the results, you need to combine the results back to the original dataset using the following command:

```bash
python core/src/influencemapper/cli.py combine -data data/test.jsonl -result batch*.jsonl study_org
python core/src/influencemapper/cli.py combine -data data/test.jsonl -result batch*.jsonl author_org
```