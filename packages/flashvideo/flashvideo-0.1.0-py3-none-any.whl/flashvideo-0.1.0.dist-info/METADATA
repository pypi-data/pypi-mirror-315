Metadata-Version: 2.1
Name: flashvideo
Version: 0.1.0
Summary: flashvideo is a lightweight framework for accelerating large video diffusion models.
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: Apache Software License
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: transformers==4.46.1
Requires-Dist: accelerate==1.0.1
Requires-Dist: tokenizers==0.20.1
Requires-Dist: albumentations==1.4.20
Requires-Dist: av==13.1.0
Requires-Dist: decord==0.6.0
Requires-Dist: einops==0.8.0
Requires-Dist: fastapi==0.115.3
Requires-Dist: gdown==5.2.0
Requires-Dist: h5py==3.12.1
Requires-Dist: idna==3.6
Requires-Dist: imageio==2.36.0
Requires-Dist: matplotlib==3.9.2
Requires-Dist: numpy==1.26.3
Requires-Dist: omegaconf==2.3.0
Requires-Dist: opencv-python==4.10.0.84
Requires-Dist: opencv-python-headless==4.10.0.84
Requires-Dist: pandas==2.2.3
Requires-Dist: pillow==10.2.0
Requires-Dist: pydub==0.25.1
Requires-Dist: pytorch-lightning==2.4.0
Requires-Dist: pytorchvideo==0.1.5
Requires-Dist: PyYAML==6.0.1
Requires-Dist: regex==2024.9.11
Requires-Dist: requests==2.31.0
Requires-Dist: scikit-learn==1.5.2
Requires-Dist: scipy==1.14.1
Requires-Dist: six==1.16.0
Requires-Dist: test-tube==0.7.5
Requires-Dist: timm==1.0.11
Requires-Dist: torchdiffeq==0.2.4
Requires-Dist: torchmetrics==1.5.1
Requires-Dist: tqdm==4.66.5
Requires-Dist: urllib3==2.2.0
Requires-Dist: uvicorn==0.32.0
Requires-Dist: scikit-video==1.1.11
Requires-Dist: imageio-ffmpeg==0.5.1
Requires-Dist: sentencepiece==0.2.0
Requires-Dist: beautifulsoup4==4.12.3
Requires-Dist: ftfy==6.3.0
Requires-Dist: moviepy==1.0.3
Requires-Dist: wandb==0.18.5
Requires-Dist: tensorboard==2.18.0
Requires-Dist: pydantic==2.9.2
Requires-Dist: gradio==5.3.0
Requires-Dist: huggingface_hub==0.26.1
Requires-Dist: protobuf==5.28.3
Requires-Dist: watch
Requires-Dist: gpustat
Requires-Dist: peft==0.13.2
Requires-Dist: liger_kernel==0.4.1
Requires-Dist: einops==0.8.0
Requires-Dist: wheel==0.44.0
Requires-Dist: loguru

<div align="center">
<img src=assets/logo.jpg width="30%"/>
</div>

FastVideo is an open-source framework for accelerating large video diffusion model.
<div align="center">
<table style="margin-left: auto; margin-right: auto; border: none;">
  <tr>
    <td>
      <img src="assets/8steps/mochi-demo.gif" width="640" alt="Mochi Demo">
    </td>
  </tr>
  <tr>
    <td style="text-align:center;">
      Get 8X diffusion boost for Mochi with FastVideo
    </td>
  </tr>
</table>
  </div>

<p align="center">
    ðŸ¤— <a href="https://huggingface.co/FastVideo/FastMochi-diffuser" target="_blank">FastMochi</a> | ðŸ¤— <a href="https://huggingface.co/FastVideo/FastHunyuan"  target="_blank">FastHunyuan</a> 
</p>

FastVideo currently offers: (with more to come)

- FastHunyuan and FastMochi: consistency distilled video diffusion models for 8x inference speedup.
- First open video DiT distillation recipes based on [PCM](https://github.com/G-U-N/Phased-Consistency-Model).
- Scalable training with FSDP, sequence parallelism, and selective activation checkpointing, with near linear scaling to 64 GPUs.
- Memory efficient finetuning with LoRA, precomputed latents, and precomputed text embeddings.


## Change Log

- ```2024/12/17```: `FastVideo` v0.1 is released.


## ðŸ”§ Installation
The code is tested on Python 3.10.0, CUDA 12.1 and H100.
```
./env_setup.sh fastvideo
```

## ðŸš€ Inference
We recommend using a GPU with 80GB of memory. To run the inference, use the following command:
### FastHunyuan
```bash
# Download the model weight
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastHunyuan --local_dir=data/FastHunyuan --repo_type=model
# CLI inference
sh scripts/inference/inference_hunyuan.sh
```
You can also inference FastHunyuan in the [official Hunyuan github](https://github.com/Tencent/HunyuanVideo).
### FastMochi

```bash
# Download the model weight
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastMochi-diffusers --local_dir=data/FastMochi-diffusers --repo_type=model
# CLI inference
bash scripts/inference/inference_mochi_sp.sh
```

## Distillation
Please refer to the [distillation guide](docs/distillation.md).

## Finetuning
Please refer to the [finetuning guide](docs/finetuning.md).

## Development Plan


## Acknowledgement
We learned and reused code from the following projects: [PCM](https://github.com/G-U-N/Phased-Consistency-Model), [diffusers](https://github.com/huggingface/diffusers), and [OpenSoraPlan](https://github.com/PKU-YuanGroup/Open-Sora-Plan).
