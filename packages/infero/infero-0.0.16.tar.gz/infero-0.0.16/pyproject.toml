[tool.poetry]
name = "infero"
version = "0.0.16"
description = "Easily download, convert, and host your models using the ONNX runtime"
authors = ["ameen-91 <mohammedameen9011@gmail.com>"]
license = "MIT"
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.12"
typer = {extras = ["all"], version = "^0.13.1"}
requests = "^2.32.3"
pyyaml = "^6.0.2"
onnx = "^1.17.0"
onnxruntime = "^1.20.1"
tqdm = "^4.67.0"
transformers = "^4.46.3"
fastapi = {extras = ["standard"], version = "^0.115.5"}
torch = "^2.5.1"
psutil = "^6.1.0"
tabulate = "^0.9.0"



[tool.poetry.group.dev.dependencies]
pytest = "^8.3.3"
ruff = "^0.7.4"


[[tool.poetry.source]]
name = "torch"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
infero = "infero.main:app"

[tool.poetry.extras]
gpu = ["onnxruntime-gpu"]

